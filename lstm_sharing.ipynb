{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try to run LSTM on RSRP values from ns-3 dual strip simulation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195970, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, read and prepare RSRP data\n",
    "file = 'DlRsrpSinrStats_hom-0_ttt-64.txt'\n",
    "h = open(file, 'r')\n",
    "hlines = h.readlines()\n",
    "\n",
    "base = []\n",
    "for line in hlines:\n",
    "    base.append(line.split())\n",
    "\n",
    "# Organize data frame\n",
    "base = pd.DataFrame(base)\n",
    "\n",
    "base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195969, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform RSRP from linear to dB\n",
    "\n",
    "base.drop(columns=[1, 3, 6, 7], inplace=True)\n",
    "\n",
    "base.columns=['time', 'IMSI', 'rsrp', 'sinr']\n",
    "\n",
    "base = base.iloc[1:]\n",
    "\n",
    "base['rsrp'] = np.log10(base['rsrp'].values.astype(float))*10\n",
    "\n",
    "base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9800, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get only RSRP values from 1 UE as time series\n",
    "myrsrp = []\n",
    "myrsrp = base.loc[base['IMSI'].astype(int)==12, 'rsrp']\n",
    "myrsrp.reset_index(drop=True, inplace=True)\n",
    "myrsrp = pd.DataFrame(myrsrp).values\n",
    "\n",
    "myrsrp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "myrsrp_norm = scaler.fit_transform(myrsrp)\n",
    "\n",
    "# train and test split \n",
    "\n",
    "rsrptrain, rsrptest = train_test_split(\n",
    "    myrsrp_norm, test_size=0.9, random_state=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev.shape (880, 100)\n",
      "real_rsrp.shape (880,)\n",
      "reshape..\n",
      "prev.shape (880, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "# Training phase\n",
    "# initialing variables\n",
    "\n",
    "prev = []\n",
    "real_rsrp = []\n",
    "\n",
    "# filling for 100-sample prediction\n",
    "for i in range(100, rsrptrain.size):\n",
    "    prev.append(rsrptrain[i-100:i, 0])\n",
    "    real_rsrp.append(rsrptrain[i, 0])\n",
    "\n",
    "# adapting formats (only 1 dimension)\n",
    "prev, real_rsrp = np.array(prev), np.array(real_rsrp)\n",
    "\n",
    "print('prev.shape',prev.shape)\n",
    "print('real_rsrp.shape',real_rsrp.shape)\n",
    "print(\"reshape..\")\n",
    "\n",
    "prev = np.reshape(prev, (prev.shape[0], prev.shape[1], 1))\n",
    "print('prev.shape',prev.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 14:16:38.395047: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-16 14:16:38.397420: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-03-16 14:16:39.398832: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "28/28 [==============================] - 22s 449ms/step - loss: 0.0540 - mean_absolute_error: 0.1795\n",
      "Epoch 2/25\n",
      "28/28 [==============================] - 12s 435ms/step - loss: 0.0330 - mean_absolute_error: 0.1462\n",
      "Epoch 3/25\n",
      "28/28 [==============================] - 12s 440ms/step - loss: 0.0318 - mean_absolute_error: 0.1449\n",
      "Epoch 4/25\n",
      "28/28 [==============================] - 13s 466ms/step - loss: 0.0292 - mean_absolute_error: 0.1358\n",
      "Epoch 5/25\n",
      "28/28 [==============================] - 15s 534ms/step - loss: 0.0263 - mean_absolute_error: 0.1311\n",
      "Epoch 6/25\n",
      "28/28 [==============================] - 14s 507ms/step - loss: 0.0266 - mean_absolute_error: 0.1343\n",
      "Epoch 7/25\n",
      "28/28 [==============================] - 16s 565ms/step - loss: 0.0255 - mean_absolute_error: 0.1289\n",
      "Epoch 8/25\n",
      "28/28 [==============================] - 15s 530ms/step - loss: 0.0259 - mean_absolute_error: 0.1298\n",
      "Epoch 9/25\n",
      "28/28 [==============================] - 14s 498ms/step - loss: 0.0265 - mean_absolute_error: 0.1322\n",
      "Epoch 10/25\n",
      "28/28 [==============================] - 21s 754ms/step - loss: 0.0264 - mean_absolute_error: 0.1319\n",
      "Epoch 11/25\n",
      "28/28 [==============================] - 16s 586ms/step - loss: 0.0244 - mean_absolute_error: 0.1267\n",
      "Epoch 12/25\n",
      "28/28 [==============================] - 16s 582ms/step - loss: 0.0243 - mean_absolute_error: 0.1249\n",
      "Epoch 13/25\n",
      "28/28 [==============================] - 27s 951ms/step - loss: 0.0245 - mean_absolute_error: 0.1263\n",
      "Epoch 14/25\n",
      "28/28 [==============================] - 20s 671ms/step - loss: 0.0257 - mean_absolute_error: 0.1295\n",
      "Epoch 15/25\n",
      "28/28 [==============================] - 13s 449ms/step - loss: 0.0249 - mean_absolute_error: 0.1282\n",
      "Epoch 16/25\n",
      "28/28 [==============================] - 16s 567ms/step - loss: 0.0234 - mean_absolute_error: 0.1235\n",
      "Epoch 17/25\n",
      "28/28 [==============================] - 17s 616ms/step - loss: 0.0248 - mean_absolute_error: 0.1278\n",
      "Epoch 18/25\n",
      "28/28 [==============================] - 17s 620ms/step - loss: 0.0242 - mean_absolute_error: 0.1244\n",
      "Epoch 19/25\n",
      "28/28 [==============================] - 18s 657ms/step - loss: 0.0240 - mean_absolute_error: 0.1255\n",
      "Epoch 20/25\n",
      "28/28 [==============================] - 17s 585ms/step - loss: 0.0238 - mean_absolute_error: 0.1254\n",
      "Epoch 21/25\n",
      "28/28 [==============================] - 16s 582ms/step - loss: 0.0238 - mean_absolute_error: 0.1258\n",
      "Epoch 22/25\n",
      "28/28 [==============================] - 16s 570ms/step - loss: 0.0230 - mean_absolute_error: 0.1231\n",
      "Epoch 23/25\n",
      "28/28 [==============================] - 17s 619ms/step - loss: 0.0240 - mean_absolute_error: 0.1258\n",
      "Epoch 24/25\n",
      "28/28 [==============================] - 17s 596ms/step - loss: 0.0236 - mean_absolute_error: 0.1250\n",
      "Epoch 25/25\n",
      "28/28 [==============================] - 14s 501ms/step - loss: 0.0230 - mean_absolute_error: 0.1228\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [979, 8820]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28922/3833295656.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# get real RSRP test values to plot and compare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mreal_rsrp_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyrsrp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8821\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m9800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mmae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_rsrp_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_absolute_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \"\"\"\n\u001b[1;32m    191\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m     )\n\u001b[1;32m    194\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0margument\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \"\"\"\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [979, 8820]"
     ]
    }
   ],
   "source": [
    "# starting regressor\n",
    "regressor = Sequential()\n",
    "regressor.add(LSTM(units = 120, return_sequences = True, input_shape = (prev.shape[1], 1)))\n",
    "\n",
    "# using dropout to avoid overfitting\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "# more layers\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "# more layers\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "# more layers\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "# final layer\n",
    "regressor.add(Dense(units = 1, activation = 'linear'))\n",
    "\n",
    "# compiling\n",
    "regressor.compile(optimizer = 'rmsprop', loss = 'mean_squared_error', metrics = ['mean_absolute_error'])\n",
    "regressor.fit(prev, real_rsrp, epochs = 25, batch_size = 32)\n",
    "\n",
    "# testing phase\n",
    "# preparing inputs for test\n",
    "inputs = myrsrp_norm[len(myrsrp_norm) - len(rsrptest) - 100:]\n",
    "inputs = inputs.reshape(-1, 1)\n",
    "\n",
    "# loop for filling variable\n",
    "x_test = []\n",
    "for i in range (100, inputs.size):\n",
    "    x_test.append(inputs[i-100:i, 0])\n",
    "\n",
    "# format adapting\n",
    "x_test = np.array(x_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "prediction = regressor.predict(x_test)\n",
    "\n",
    "# undo normalization for better viewing our results\n",
    "prediction = scaler.inverse_transform(prediction)\n",
    "\n",
    "# get real RSRP test values to plot and compare\n",
    "real_rsrp_test = myrsrp[8821:9800, :]\n",
    "mae = mean_absolute_error(real_rsrp_test, prediction)\n",
    "\n",
    "# visualization\n",
    "plt.plot(real_rsrp_test, color = 'red', label = 'Real RSRP')\n",
    "plt.plot(prediction, color = 'blue', label = 'Prediction')\n",
    "plt.title('RSRP values prediction')\n",
    "plt.xlabel('Time (samples)')\n",
    "plt.ylabel('RSRP (dB)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f9569f1cf38496a20bb63a812204f6e6a0e56470429a70e95e636c231b9bbf1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
